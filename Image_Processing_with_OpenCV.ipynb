{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96221fbd-32e3-49a8-aef9-21570d1eaeb4",
   "metadata": {},
   "source": [
    "# Edge Detection Filters\n",
    "Let's learn about Sobel filters. The kernels are very simple. \n",
    "\n",
    "To detect vertical edges, we can use this kernel:\n",
    "<math>\n",
    "\\begin{bmatrix} \n",
    "+1 & 0 & -1  \\\\\n",
    "+2 & 0 & -2 \\\\\n",
    "+1 & 0 & -1 \n",
    "\\end{bmatrix} \n",
    "\n",
    "To detect horizontal edges, we can use this kernel:\n",
    "\\begin{bmatrix} \n",
    "+1 & +2 & +1\\\\\n",
    " 0 & 0 & 0 \\\\\n",
    "-1 & -2 & -1\n",
    "\\end{bmatrix} \n",
    "\n",
    "</math>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b5e510-57de-412f-ab01-6d6bafe3dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's work with a picture of penguins\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_formats = 'retina'\n",
    "from matplotlib import rcParams\n",
    "import cv2\n",
    "from EC_CV import * \n",
    "\n",
    "rcParams['figure.figsize'] = (20,8)\n",
    "\n",
    "img = plt.imread('./Image_for_Image_Processing_with_OpenCV/penguins.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd59a91-588a-407a-9605-12f97a63700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use a vertical Sobel filter\n",
    "\n",
    "kernel = np.matrix([[1, 0, -1], \n",
    "                    [2, 0, -2],\n",
    "                    [1, 0, -1]])\n",
    "\n",
    "vr_edges = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\n",
    "plt.imshow(vr_edges,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e876f39c-e3a3-4d1d-a4ba-5807fd436d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's use the opposite vertical Sobel filter\n",
    "\n",
    "kernel = np.matrix([[-1, 0, 1], \n",
    "                    [-2, 0, 2],\n",
    "                    [-1, 0, 1]])\n",
    "\n",
    "vl_edges = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\n",
    "\n",
    "rcParams['figure.figsize'] = 20,8\n",
    "\n",
    "# display images\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(vr_edges,cmap='gray')\n",
    "ax[1].imshow(vl_edges,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39251237-716c-436e-a4d4-95f33675d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add the two vertical edge images\n",
    "\n",
    "v_edges = cv2.add(vr_edges,vl_edges)\n",
    "plt.imshow(v_edges,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4a4c8-b3bc-47a1-98b7-e3c4e8c2fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do the same for horizontal Sobel filters\n",
    "\n",
    "kernel = np.matrix([[ 1,  2,  1], \n",
    "                    [ 0,  0,  0],\n",
    "                    [-1, -2, -1]])\n",
    "\n",
    "hd_edges = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\n",
    "\n",
    "kernel = np.matrix([[-1, -2, -1], \n",
    "                    [ 0,  0,  0],\n",
    "                    [ 1,  2,  1]])\n",
    "\n",
    "hu_edges = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\n",
    "\n",
    "rcParams['figure.figsize'] = 20,8\n",
    "\n",
    "# display images\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(hd_edges,cmap='gray')\n",
    "ax[1].imshow(hu_edges,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6391af-aa3b-4296-84ed-1a320331380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add the two images\n",
    "\n",
    "h_edges = cv2.add(hd_edges,hu_edges)\n",
    "plt.imshow(h_edges, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e08b477-0467-4b26-b4d2-11729af21d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's add all edge images\n",
    "\n",
    "all_edges = cv2.add(h_edges,v_edges) \n",
    "plt.imshow(all_edges, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e629c91-8f0f-46ee-8566-bfcd24cd8ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for fun, let's turn it into black and white\n",
    "\n",
    "(thresh, blackAndWhiteImage) = cv2.threshold(all_edges, 127, 255, cv2.THRESH_BINARY)\n",
    "plt.imshow(blackAndWhiteImage, cmap='gray')\n",
    "print(np.shape(blackAndWhiteImage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c9c81-cd0f-4e3f-9dfb-c6ad703959fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for fun, let's turn it into black and white\n",
    "\n",
    "plt.imshow(cv2.bitwise_not(blackAndWhiteImage), cmap='gray')\n",
    "print(np.shape(blackAndWhiteImage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d30e94",
   "metadata": {},
   "source": [
    "# Average Filters\n",
    "Let's experiment with average filters, which use the kernel to calculate the average of all overlapping pixels. This average is the new pixel, and it produces a blurring effect in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff747883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's work with the picture of a house\n",
    "\n",
    "\n",
    "rcParams['figure.figsize'] = (20,8)\n",
    "\n",
    "img = plt.imread('./Image_for_Image_Processing_with_OpenCV/house.jpg')\n",
    "plt.imshow(img)\n",
    "print(np.shape(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc29ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV's filter2D function works with color and grayscale images\n",
    "\n",
    "kernel = np.ones((7, 7), np.float32) / 49\n",
    "blurred = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\n",
    "plt.imshow(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d465475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the images side by side\n",
    "\n",
    "rcParams['figure.figsize'] = (20,8)\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5467ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 20)\n",
    "\n",
    "# display images\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(img[:,400:800])\n",
    "ax[1].imshow(blurred[:,400:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fc5587",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 20)\n",
    "\n",
    "# display images\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(img[:,400:800])\n",
    "ax[1].imshow(blurred[:,400:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83362f6f",
   "metadata": {},
   "source": [
    "# Median Filters\n",
    "Not all filters perform the same weighted sum operation. Median filters can also blur images by picking the median value instead of the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2760d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's work with a grainy picture\n",
    "\n",
    "rcParams['figure.figsize'] = (24, 10)\n",
    "\n",
    "img = plt.imread('./Image_for_Image_Processing_with_OpenCV/field.jpg')\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf03be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV's functions work with color and grayscale images\n",
    "\n",
    "median = cv2.medianBlur(img,5)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4715afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see an average blur side by side with a median blur\n",
    "\n",
    "rcParams['figure.figsize'] = (20,8)\n",
    "\n",
    "kernel = np.ones((5, 5), np.float32) / 25\n",
    "average = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\n",
    "\n",
    "# display images\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(average)\n",
    "ax[1].imshow(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc11e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's zoom in to the leftmost section\n",
    "\n",
    "rcParams['figure.figsize'] = (20, 20)\n",
    "\n",
    "# display images\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(average[:,:400])\n",
    "ax[1].imshow(median[:,:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now a middle section\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(average[:,400:800])\n",
    "ax[1].imshow(median[:,400:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, the rightmost section\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(average[:,800:1200])\n",
    "ax[1].imshow(median[:,800:1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f8b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see it for a different picture\n",
    "\n",
    "rcParams['figure.figsize'] = (24, 10)\n",
    "\n",
    "img = plt.imread('./Image_for_Image_Processing_with_OpenCV/workers.jpg')\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV's functions work with color and grayscale images\n",
    "\n",
    "median = cv2.medianBlur(img,3)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49293273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see an average blur side by side with a median blur\n",
    "\n",
    "rcParams['figure.figsize'] = (20,8)\n",
    "\n",
    "kernel = np.ones((3, 3), np.float32) / 9\n",
    "average = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\n",
    "\n",
    "# display images\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(average)\n",
    "ax[1].imshow(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df3a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's zoom in to the leftmost section\n",
    "\n",
    "rcParams['figure.figsize'] = (20, 20)\n",
    "\n",
    "# display images\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(average[:,:400])\n",
    "ax[1].imshow(median[:,:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54478ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now a middle section\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(average[:,400:800])\n",
    "ax[1].imshow(median[:,400:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1cc318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, the rightmost section\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(average[:,700:1100])\n",
    "ax[1].imshow(median[:,700:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69233f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you try it with this picture of a face.\n",
    "# Experiment with several kernel sizes.\n",
    "\n",
    "rcParams['figure.figsize'] = (24, 10)\n",
    "\n",
    "img = plt.imread('./Image_for_Image_Processing_with_OpenCV/face.jpg')\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e53aa",
   "metadata": {},
   "source": [
    "# Gaussian Filters\n",
    "While average filters calculate the average in the neighborhood of the pixel of interest, a gaussian filter calculates a weighted average using a kernel with values that match the gaussian bell curve.\n",
    "Here's a 3x3 gaussian kernel:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "1 & 2 & 1  \\\\\n",
    "2 & 4 & 2 \\\\ \n",
    "1 & 2 & 1 \n",
    "\\end{bmatrix} \n",
    "* {1\\over16}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's work with the picture of a house\n",
    "\n",
    "rcParams['figure.figsize'] = 20,8\n",
    "\n",
    "img = plt.imread('./Image_for_Image_Processing_with_OpenCV/house.jpg')\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba0bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV's GaussianBlur function works with color and grayscale images\n",
    "\n",
    "blurred = cv2.GaussianBlur(img,(7,7),cv2.BORDER_DEFAULT)\n",
    "plt.imshow(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see all 3 blur filters at once\n",
    "\n",
    "rcParams['figure.figsize'] = 18,14\n",
    "kernel = np.ones((15, 15), np.float32) / 225\n",
    "blur1 = cv2.medianBlur(img,15)\n",
    "blur2 = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\n",
    "blur3 = cv2.GaussianBlur(img,(15,15),cv2.BORDER_DEFAULT)\n",
    "titles = ['Original Image', 'Median Filter', 'Average Filter', 'Gaussian Filter']\n",
    "images = [img, blur1, blur2, blur3]\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i])\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d36e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's zoom in to see the main entrance. \n",
    "\n",
    "rcParams['figure.figsize'] = 20, 12\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(blur2[200:550,150:450])\n",
    "ax[1].imshow(blur3[200:550,150:450])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d037573",
   "metadata": {},
   "source": [
    "# Creating a Convolution Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a806c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rcParams['figure.figsize'] = (10, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e497eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a color image\n",
    "# Copy an image file of your own in this folder, \n",
    "# open it and display it.\n",
    "\n",
    "img  = plt.imread('./Image_for_Image_Processing_with_OpenCV/komodo.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb3addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create your Own Kernel.\n",
    "\n",
    "# Modify this kernel definition\n",
    "kernel = np.matrix([[2,  1,  0], \n",
    "                    [1,  0, -1],\n",
    "                    [0, -1, -2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b50f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to test kernel\n",
    "\n",
    "filtered1 = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\n",
    "rcParams['figure.figsize'] = 20,8\n",
    "\n",
    "# display images\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(img,cmap='gray')\n",
    "ax[1].imshow(filtered1,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aff74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a second kernel\n",
    "\n",
    "\n",
    "kernel = np.matrix([[0, -1, -2], \n",
    "                    [1,  0, -1],\n",
    "                    [2,  1,  0]])\n",
    "\n",
    "filtered2 = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\n",
    "rcParams['figure.figsize'] = 20,8\n",
    "\n",
    "# display images\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(img,cmap='gray')\n",
    "ax[1].imshow(filtered2,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e5a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see the two images side by side\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(filtered1,cmap='gray')\n",
    "ax[1].imshow(filtered2,cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
